{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /Users/reejungkim/.cache/torch/hub/master.zip\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"torchvision>=0.8.1\" not found, attempting AutoUpdate...\n",
      "Collecting torchvision>=0.8.1\n",
      "  Downloading torchvision-0.13.1-cp37-cp37m-macosx_10_9_x86_64.whl (1.3 MB)\n",
      "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.3/1.3 MB 19.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/envs/myenv/lib/python3.7/site-packages (from torchvision>=0.8.1) (9.2.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/myenv/lib/python3.7/site-packages (from torchvision>=0.8.1) (4.1.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/myenv/lib/python3.7/site-packages (from torchvision>=0.8.1) (1.19.2)\n",
      "Collecting torch==1.12.1\n",
      "  Downloading torch-1.12.1-cp37-none-macosx_10_9_x86_64.whl (137.7 MB)\n",
      "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 137.7/137.7 MB 16.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/myenv/lib/python3.7/site-packages (from torchvision>=0.8.1) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/envs/myenv/lib/python3.7/site-packages (from requests->torchvision>=0.8.1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/myenv/lib/python3.7/site-packages (from requests->torchvision>=0.8.1) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/myenv/lib/python3.7/site-packages (from requests->torchvision>=0.8.1) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/myenv/lib/python3.7/site-packages (from requests->torchvision>=0.8.1) (1.26.9)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.7.1\n",
      "    Uninstalling torch-1.7.1:\n",
      "      Successfully uninstalled torch-1.7.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.8.0a0\n",
      "    Uninstalling torchvision-0.8.0a0:\n",
      "      Successfully uninstalled torchvision-0.8.0a0\n",
      "Successfully installed torch-1.12.1 torchvision-0.13.1\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /Users/reejungkim/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "YOLOv5 üöÄ 2022-9-13 Python-3.7.13 torch-1.7.1 CPU\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f811746f12465c96abb38af8d2d673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/14.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Saved 1 image to \u001b[1mruns/detect/exp\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 720x1280 2 persons, 2 ties\n",
      "Speed: 821.6ms pre-process, 242.7ms inference, 1.8ms NMS per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>742.974792</td>\n",
       "      <td>48.395599</td>\n",
       "      <td>1141.844604</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>0.881052</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>442.007629</td>\n",
       "      <td>437.522430</td>\n",
       "      <td>496.653992</td>\n",
       "      <td>709.973511</td>\n",
       "      <td>0.675214</td>\n",
       "      <td>27</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123.024261</td>\n",
       "      <td>193.287323</td>\n",
       "      <td>715.661987</td>\n",
       "      <td>719.723877</td>\n",
       "      <td>0.665813</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>982.803162</td>\n",
       "      <td>308.417358</td>\n",
       "      <td>1027.365845</td>\n",
       "      <td>419.987000</td>\n",
       "      <td>0.260076</td>\n",
       "      <td>27</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xmin        ymin         xmax        ymax  confidence  class    name\n",
       "0  742.974792   48.395599  1141.844604  720.000000    0.881052      0  person\n",
       "1  442.007629  437.522430   496.653992  709.973511    0.675214     27     tie\n",
       "2  123.024261  193.287323   715.661987  719.723877    0.665813      0  person\n",
       "3  982.803162  308.417358  1027.365845  419.987000    0.260076     27     tie"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "# Images\n",
    "imgs = ['https://ultralytics.com/images/zidane.jpg']  # batch of images\n",
    "\n",
    "# Inference\n",
    "results = model(imgs)\n",
    "\n",
    "# Results\n",
    "results.print()\n",
    "results.save()  # or .show()\n",
    "\n",
    "results.xyxy[0]  # img1 predictions (tensor)\n",
    "results.pandas().xyxy[0]  # img1 predictions (pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e47b1a34c05c1e3b83a62d7885c9d1b5ef8a0522d3be0182d0a008ec409b2b3d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
